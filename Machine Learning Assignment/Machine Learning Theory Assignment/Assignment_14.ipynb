{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2aa57f2",
   "metadata": {},
   "source": [
    "# ---------------------- Assignment 14 ----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111120c6",
   "metadata": {},
   "source": [
    "### Q1. What is the concept of supervised learning? What is the significance of the name ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397884b3",
   "metadata": {},
   "source": [
    "**Ans:** \n",
    "Supervised learning is a machine learning paradigm where the model is trained on a labeled dataset, meaning that each input data point is associated with a corresponding target label or output. The goal of supervised learning is to learn a mapping function from the input variables to the output variables based on the labeled training data. This learned mapping function can then be used to make predictions or classify new, unseen data points. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae857d4",
   "metadata": {},
   "source": [
    "### Q2. In the hospital sector, offer an example of supervised learning ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda9f6d4",
   "metadata": {},
   "source": [
    "**Ans:** In the hospital sector, supervised learning can be applied to various tasks to improve patient care, optimize operations, and enhance decision-making processes. One example of supervised learning in the hospital sector is the prediction of patient readmission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c981ac1e",
   "metadata": {},
   "source": [
    "### Q3. Give three supervised learning examples ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e74d1e",
   "metadata": {},
   "source": [
    "**Ans:** Example of Supervised Learning Algorithms are:\n",
    "- Linear Regression.\n",
    "- Logistic Regression.\n",
    "- k-Nearest Neighbor.\n",
    "- Naive Bayes.\n",
    "- Decision Trees.\n",
    "- Support Vector Machine (SVM)\n",
    "- Random Forest.\n",
    "- Gradient Boosting Machines (GBM)\n",
    "- Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ab2a64",
   "metadata": {},
   "source": [
    "### Q4. In supervised learning, what are classification and regression ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84be079f",
   "metadata": {},
   "source": [
    "**Ans:** Fundamentally, classification is about predicting a label and regression is about predicting a quantity. That classification is the problem of predicting a discrete class label output for an example. That regression is the problem of predicting a continuous quantity output for an example.\n",
    "\n",
    "| Feature                  | Classification                                             | Regression                                                  |\n",
    "|--------------------------|-------------------------------------------------------------|-------------------------------------------------------------|\n",
    "| **Task Type**            | Predicting the class label or category of a data point.     | Predicting a continuous numeric value.                       |\n",
    "| **Output**               | Discrete and categorical values (e.g., classes, labels).    | Continuous numeric values (e.g., prices, quantities).        |\n",
    "| **Example Applications** | Spam email detection, image classification, sentiment analysis. | Stock price prediction, house price estimation, demand forecasting. |\n",
    "| **Evaluation Metrics**   | Accuracy, precision, recall, F1-score, ROC AUC.            | Mean Absolute Error (MAE), Mean Squared Error (MSE), R-squared. |\n",
    "| **Model Complexity**     | Can be simple (e.g., logistic regression) or complex (e.g., neural networks). | Can be simple (e.g., linear regression) or complex (e.g., ensemble methods). |\n",
    "| **Decision Boundary**    | Decision boundary separates different classes in the feature space. | No distinct boundary; the model predicts a continuous output. |\n",
    "| **Loss Function**        | Typically cross-entropy loss or hinge loss for binary classification. | Typically mean squared error (MSE) or mean absolute error (MAE). |\n",
    "| **Examples of Algorithms** | Logistic Regression, Decision Trees, Random Forest, Support Vector Machines (SVM), Neural Networks. | Linear Regression, Polynomial Regression, Decision Trees, Random Forest, Gradient Boosting. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be2162e",
   "metadata": {},
   "source": [
    "### Q5. Give some popular classification algorithms as examples ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b5e11c",
   "metadata": {},
   "source": [
    "**Ans:** Popular algorithms that can be used for multi-class classification include:\n",
    "- Logistic Regression\n",
    "- k-Nearest Neighbors\n",
    "- Decision Trees.\n",
    "- Naive Bayes\n",
    "- Support Vectoe Machine(SVM)\n",
    "- KNN\n",
    "- Random Forest \n",
    "- Gradient Boosting Machines (GBM)\n",
    "- Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96163dd",
   "metadata": {},
   "source": [
    "### 6. Briefly describe the SVM model ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2398e09",
   "metadata": {},
   "source": [
    "**Ans:** Support Vector Machine (SVM) is a supervised learning algorithm used for classification and regression tasks. In the context of classification, SVM aims to find the optimal hyperplane that separates data points of different classes with the maximum margin. The basic idea is to identify the decision boundary that maximizes the margin between the nearest data points of different classes, known as support vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3b649e",
   "metadata": {},
   "source": [
    "### Q7. In SVM, what is the cost of misclassification ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4018c29b",
   "metadata": {},
   "source": [
    "**Ans:** In Support Vector Machine (SVM), the cost of misclassification refers to the penalty incurred for classifying a data point incorrectly.\n",
    "\n",
    "In the context of SVM, the cost of misclassification is controlled by the regularization parameter (C). This parameter determines the trade-off between maximizing the margin (i.e., finding a decision boundary with larger margin) and minimizing the classification error (i.e., allowing for more misclassified points).\n",
    "\n",
    "A smaller value of C results in a larger margin but may allow for more misclassified points, effectively reducing the penalty for misclassification. On the other hand, a larger value of C imposes a smaller margin but reduces the number of misclassified points, resulting in a higher penalty for misclassification.\n",
    "\n",
    "In summary, the cost of misclassification in SVM is indirectly controlled by the regularization parameter C, which balances the desire for a wider margin with the need to minimize classification errors. Adjusting the value of C allows users to tune the model's behavior according to the specific requirements of the problem at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54020cf8",
   "metadata": {},
   "source": [
    "### Q8. In the SVM model, define Support Vectors ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130acaa5",
   "metadata": {},
   "source": [
    "**Ans:** Support vectors are data points that are closer to the hyperplane and influence the position and orientation of the hyperplane. Using these support vectors, we maximize the margin of the classifier. Deleting the support vectors will change the position of the hyperplane. These are the points that help us build our SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db681d1",
   "metadata": {},
   "source": [
    "### Q9. In the SVM model, define the kernel ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d56a9dd",
   "metadata": {},
   "source": [
    "**Ans:** SVM algorithms use a set of mathematical functions that are defined as the kernel. The function of kernel is to take data as input and transform it into the required form. These functions can be different types. For example linear, nonlinear, polynomial, radial basis function (RBF), and sigmoid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b686929",
   "metadata": {},
   "source": [
    "### Q10. What are the factors that influence SVM's effectiveness ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff033749",
   "metadata": {},
   "source": [
    "**Ans:** SVM or Support Vector Machine is a linear model for classification and regression problems. It can solve linear and non-linear problems and work well for many practical problems. The idea of SVM is simple: The algorithm creates a line or a hyperplane which separates the data into classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e636eaf",
   "metadata": {},
   "source": [
    "### Q11. What are the benefits of using the SVM model ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ed07d2",
   "metadata": {},
   "source": [
    "**Ans:** SVM works relatively well when there is a clear margin of separation between classes. SVM is more effective in high dimensional spaces. SVM is effective in cases where the number of dimensions is greater than the number of samples.SVM is relatively memory efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64feb7de",
   "metadata": {},
   "source": [
    "### Q12.  What are the drawbacks of using the SVM model ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c3bd36",
   "metadata": {},
   "source": [
    "**Ans:** SVM algorithm is not suitable for large data sets. SVM does not perform very well when the data set has more noise i.e. target classes are overlapping. In cases where the number of features for each data point exceeds the number of  training data samples, the SVM will underperform.\n",
    "```python\n",
    "1. Difficulty in choosing appropriate kernels\n",
    "2. Sensitivity to scaling\n",
    "3. Memory and computational requirements\n",
    "4. Limited interpretability\n",
    "5. Difficulty in handling noisy datasets\n",
    "6. Binary classification limitation\n",
    "7. Limited scalability to large datasets\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcec9c51",
   "metadata": {},
   "source": [
    "### Q13. Notes should be written on\n",
    "1. The kNN algorithm has a validation flaw.\n",
    "2. In the kNN algorithm, the k value is chosen.\n",
    "3. A decision tree with inductive bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b271402",
   "metadata": {},
   "source": [
    "**Ans:** The Short notes on below topics is:\n",
    "- **The kNN algorithm has a validation flaw.**\n",
    "The relatively low accuracy of kNN is caused by several factors. One of them is that every characteristic of the method has the same result on calculating distance. The solution of this problem is to give weight to each data characteristic.\n",
    "- **In the kNN algorithm, the k value is chosen.**\n",
    "The optimal K value usually found is the square root of N, where N is the total number of samples. Use an error plot or accuracy plot to find the most favorable K value. KNN performs well with multi-label classes, but you must be aware of the outliers.\n",
    "- **A decision tree with inductive bias**\n",
    "Shorter trees are preferred over longer ones. Trees that place high information gain attributes close to the root are preferred over those that do not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5830b034",
   "metadata": {},
   "source": [
    "### Q14. What are some of the benefits of the kNN algorithm ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a19b86",
   "metadata": {},
   "source": [
    "**Ans:** Some Advantages of KNN are:\n",
    "- Quick calculation time.\n",
    "- Simple algorithm – to interpret.\n",
    "- Versatile – useful for regression and classification.\n",
    "- High accuracy – you do not need to compare with better-supervised learning models.\n",
    "- Simplicity\n",
    "- Non-parametric\n",
    "- No Training Phase\n",
    "- Versatility\n",
    "- Localized Learning\n",
    "- Robust to Outliers\n",
    "- No Assumptions about Data Distribution\n",
    "- Adaptable to New Data\n",
    "- Parameter Tuning\n",
    "- Intuitive Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d2525e",
   "metadata": {},
   "source": [
    "### Q15. What are some of the kNN algorithm's drawbacks ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2db68b8",
   "metadata": {},
   "source": [
    "**Ans:** Some Disadvantages of KNN are:\n",
    "- Accuracy depends on the quality of the data.\n",
    "- With large data, the prediction stage might be slow.\n",
    "- Sensitive to the scale of the data and irrelevant features.\n",
    "- Require high memory – need to store all of the training data.\n",
    "- Given that it stores all of the training, it can be computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb583d7",
   "metadata": {},
   "source": [
    "### Q16. Explain the decision tree algorithm in a few words ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3590b9e3",
   "metadata": {},
   "source": [
    "**Ans:** A decision tree is a graphical representation of all the possible solutions to a decision based on certain conditions. Tree models where the target variable can take a finite set of values are called classification trees and target variable can take continuous values (numbers) are called regression trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7bb76f",
   "metadata": {},
   "source": [
    "### Q17. What is the difference between a node and a leaf in a decision tree ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b066b40",
   "metadata": {},
   "source": [
    "**Ans:** A decision tree is a flowchart-like structure in which each internal node represents a \"test\" on an attribute  (e.g. whether a coin flip comes up heads or tails), each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75f2f0e",
   "metadata": {},
   "source": [
    "### Q18. What is a decision tree's entropy ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16c4feb",
   "metadata": {},
   "source": [
    "**Ans:** Entropy helps us to build an appropriate decision tree for selecting the best splitter. Entropy can be defined as a measure of the purity of the sub split. Entropy always lies between 0 to 1. The entropy of any split can be calculate by this formula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcb9419",
   "metadata": {},
   "source": [
    "### Q19. In a decision tree, define knowledge gain ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6734f8f",
   "metadata": {},
   "source": [
    "**Ans:** Information gain is the reduction in entropy or surprise by transforming a dataset and is often used in training decision trees.Information gain is calculated by comparing the entropy of the dataset before and after a transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a6ac5d",
   "metadata": {},
   "source": [
    "### Q20. Choose three advantages of the decision tree approach and write them down ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a727a3",
   "metadata": {},
   "source": [
    "**Ans:**  Advantages of Decision Trees : \n",
    "- Easy to read and interpret. One of the advantages of decision trees is that their outputs are easy to read and interpret without requiring statistical knowledge.\n",
    "- Easy to prepare.\n",
    "- Less data cleaning required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093ca2a6",
   "metadata": {},
   "source": [
    "### Q21. Make a list of three flaws in the decision tree process ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10f88d4",
   "metadata": {},
   "source": [
    "**Ans:** Issues in Decision Tree Learning : \n",
    "- Overfitting the data.\n",
    "- Guarding against bad attribute choices.\n",
    "- Handling continuous valued attributes.\n",
    "- Handling missing attribute values.\n",
    "- Handling attributes with differing costs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d80780",
   "metadata": {},
   "source": [
    "### Q22. Briefly describe the random forest model ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5468db2",
   "metadata": {},
   "source": [
    "**Ans:** The random forest is a classification algorithm consisting of many decisions trees. It uses bagging and feature randomness when building each individual tree to try to create an uncorrelated forest of trees whose prediction by committee is more accurate than that of any individual tree."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
